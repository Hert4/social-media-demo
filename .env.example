# LLM Configuration
# Copy this file to .env and fill in your values

# Base URL for OpenAI-compatible API
# - DEV: you can use Vite proxy: /llm-proxy/v1
# - PROD (Vercel): use serverless function proxy: /api/llm-proxy/v1
VITE_LLM_BASE_URL=/api/llm-proxy/v1

# API Key (keep this secret!)
VITE_LLM_API_KEY=your-api-key-here

# Model name
VITE_LLM_MODEL=gpt-4o
