# LLM Configuration
# Copy this file to .env and fill in your values

# Base URL for OpenAI-compatible API
# - DEV: you can use Vite proxy: /llm-proxy/v1
# - PROD (Vercel): use serverless function proxy: /api/llm-proxy/v1
VITE_LLM_BASE_URL=/api/llm-proxy/v1

# API Key (keep this secret!)
VITE_LLM_API_KEY=your-api-key-here

# Model name
VITE_LLM_MODEL=gpt-4o

# Environment variables for serverless function (required for production)
LLM_BASE_URL=https://especially-rss-searched-villages.trycloudflare.com
LLM_API_KEY=misa_misa_00t07fh7_ZFRMf6rOUaVHTv6CZH0uOzAx_LDP1IeWM
